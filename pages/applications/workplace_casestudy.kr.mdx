# 학위가 필요한 직업을 분류한 사례연구

[Clavié et al., 2023](https://arxiv.org/abs/2303.07142)는 프롬프트 엔지니어링을 적용한 미디엄 스케일의 텍스트 분류 유스케이스 사례연구를 발표했습니다. 분류 작업을 통해서 특정 직업이 대학을 갓 졸업한 사람에게 꼭 맞는 "신입 레벨" 인지, 여러 프롬프트 엔지니어링 테크닉을 사용하여 평가한 뒤 GPT-3.5 (`gpt-3.5-turbo`)를 사용하여 결과를 공유했습니다.

이 연구는 강력한 베이스라인인 DeBERTa-V3를 포함한 여러 다른 모델들을 LLM이 가뿐히 능가했음을 증명합니다. 또한 `gpt-3.5-turbo`가 구 버전의 GPT3 variants의 모든 키 메트릭에서 두각을 나타냈음을 보여주었습니다만, 템플릿에 한정하여 추가 출력 파싱을 필요로 할 만큼 다른 variants보다는 조금 떨어진 성능을 확인할 수 있었습니다.

프롬프트 엔지니어링 접근법에서 얻은 주요 결과는 다음과 같습니다:

- 전문가의 지식이 필요하지 않은 이러한 단순 작업의 경우, 모든 실험에서 Few-shot CoT 프롬프팅이 Zero-shot 프롬프팅에 비해 상대적으로 낮은 퍼포먼스를 보여주었습니다.
- 프롬프트는 올바른 추론 도출에 엄청난 영향을 미칩니다. 모델에게 직업을 분류하라고 간단하게 명령했을 때에는 65.6의 F1 점수를 얻었으나, 포스트-프롬프트 엔지니어링 모델은 91.7의 F1 점수를 보여주었습니다.
- 모델을 템플릿에 강제로 적용하려 한 모든 경우에 성능이 저하되었습니다. (이 방법은 논문 뒤 쪽의 GPT-4를 사용한 초기 테스트에서 사라졌습니다.)
- 아주 작은 수정사항이 성능에 엄청난 영향을 미쳤습니다.
  - 아래 표에서 모든 수정사항에 따른 결과를 확인하세요.
  - 적절한 지시를 내리고, 키 포인트를 반복하는 것이 가장 큰 성능 동력으로 나타났습니다.
  - 모델에게 (사람)이름을 지어주고 불러주는 것은 F1 점수를 증가시켰습니다.

### 실험에 쓰인 프롬프트 수정사항들

| 약어     | 설명                                                                              |
| -------- | --------------------------------------------------------------------------------- |
| Baseline | 채용 공고를 제공하고 갓 졸업한 신입에게 적합한지 묻습니다.                        |
| CoT      | 쿼리를 날리기 전에 몇 가지 정확한 예시를 제공합니다.                              |
| Zero-CoT | 모델에게 단계별로 추론한 뒤 정답을 제시하도록 요구합니다.                         |
| rawinst  | 역할 및 작업에 대한 지침을 사용자 메시지에 추가하여 제공합니다.                   |
| sysinst  | 시스템 메시지로서의 역할과 작업에 대한 지침을 제공합니다.                         |
| bothinst | 시스템 메시지로서의 역할과 사용자 메시지로서의 작업을 사용하여 명령을 분할합니다. |
| mock     | 토론 내용을 인식하는 부분을 따라하여 작업 지시를 내립니다.                        |
| reit     | 주요 요소를 반복하여 지시를 보강합니다.                                           |
| strict   | 모델에게 주어진 템플릿을 엄격히 준수하여 답변하도록 요청합니다.                   |
| loose    | 주어진 템플릿 뒤에 최종 답변만 반환하도록 요청합니다.                             |
| right    | 모델에게 올바른 결론에 도달하도록 요청합니다.                                     |
| info     | 일반적인 추론 실패를 해결하기 위한 추가 정보를 제공합니다.                        |
| name     | 모델에게 이름을 지어주고 대화 시 사용합니다.                                      |
| pos      | 쿼리를 날리기 전 모델에게 긍정적인 피드백을 제공합니다.                           |

### 위의 프롬프트 수정사항이 성능에 미치는 영향

|                                         | 정확도   | 리콜   | F1       | 템플릿 고착도 |
| --------------------------------------- | -------- | ------ | -------- | ------------- |
| _Baseline_                              | _61.2_   | _70.6_ | _65.6_   | _79%_         |
| _CoT_                                   | _72.6_   | _85.1_ | _78.4_   | _87%_         |
| _Zero-CoT_                              | _75.5_   | _88.3_ | _81.4_   | _65%_         |
| _+rawinst_                              | _80_     | _92.4_ | _85.8_   | _68%_         |
| _+sysinst_                              | _77.7_   | _90.9_ | _83.8_   | _69%_         |
| _+bothinst_                             | _81.9_   | _93.9_ | _87.5_   | _71%_         |
| +bothinst+mock                          | 83.3     | 95.1   | 88.8     | 74%           |
| +bothinst+mock+reit                     | 83.8     | 95.5   | 89.3     | 75%           |
| _+bothinst+mock+reit+strict_            | _79.9_   | _93.7_ | _86.3_   | _**98%**_     |
| _+bothinst+mock+reit+loose_             | _80.5_   | _94.8_ | _87.1_   | _95%_         |
| +bothinst+mock+reit+right               | 84       | 95.9   | 89.6     | 77%           |
| +bothinst+mock+reit+right+info          | 84.9     | 96.5   | 90.3     | 77%           |
| +bothinst+mock+reit+right+info+name     | 85.7     | 96.8   | 90.9     | 79%           |
| +bothinst+mock+reit+right+info+name+pos | **86.9** | **97** | **91.7** | 81%           |

템플릿 고착도란 요구한 형식으로 모델이 응답한 빈도를 나타냅니다.
Template stickiness refers to how frequently the model answers in the desired format.
