# 사실성

LLM은 일관성과 설득력을 지닌 응답을 생성하는 경향이 있지만 때로는 조작된 것일 수 있습니다. 프롬프트를 개선함으로써 보다 정확하고 사실에 기반한 응답을 생성하도록 사실에 어긋난 응답을 생성할 가능성을 줄일 수 있습니다.

몇 가지 해결책은 다음과 같습니다:

- 모델이 조작 텍스트를 생성할 가능성을 줄이기 위해 컨텍스트의 일부로서 근본에 가까운 정답(예를 들어 관련 기사 단락이나 Wikipedia 엔트리)을 제공하기
- 확률 파라미터의 개수를 줄이고 답을 모르는 경우에는 (예를 들어, 모르겠어요)라고 인정하도록 지시함으로써 모델이 엉뚱한 대답을 하지않도록 설정하기
- 프롬프트에 알고 있는 것과 모르는 것의 양쪽 질문과 응답의 예시를 조합하기

간단한 예시를 살펴봅시다:

_프롬프트:_

```
Q: 원자가 뭐야?
A: 원자란 모든 것을 구성하는 작은 입자입니다.

Q: Alvan Muntz가 누구야?
A: ?

Q: Kozar-09가 뭐야?
A: ?

Q: 화성에는 위성이 몇 개 있어?
A: 포보스와 데이모스라는 두 가지의 위성이 있습니다.

Q: Neto Beto Roberto가 누구야?
```

_출력:_

```
A: ?
```

'Neto Beto Roberto'는 제가 그냥 지어낸 이름이기 때문에 모델은 알맞은 대답을 한 셈입니다. 질문에 변형을 가해서 모델이 제대로 답변하는 지 실험해보세요. 지금까지 배워온 것을 바탕으로 더 개선하는 여러 방법이 있습니다.
