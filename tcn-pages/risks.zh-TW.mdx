# 風險和誤用

import { Callout } from 'nextra-theme-docs'

我們已經看到能透過`少量樣本提示 (few-shot)`和`思維鏈提示 (chain-of-thought)`這類技術，得出對各類型任務都很有效的良好提示。當我們打算在`大型語言模型 (LLM)`上構建實際應用時，最重要而不可忽視的事情，是務必思考那些關於`語言模型 (LM)`上的誤用、風險和實作安全性。

這個單元將以`提示注入 (prompt injection)`等技術的角度切入，來重點關注那些 LLM 帶來的風險和誤用。也會提到有害的行為，及如何透過有效的提示技術來潛移默化地減少它們。其它有趣的主題，包含：普遍性、校正、偏見、社會偏見和真實性等幾個例子。

<Callout emoji="⚠️">
  本單元還在趕工中。
</Callout>
