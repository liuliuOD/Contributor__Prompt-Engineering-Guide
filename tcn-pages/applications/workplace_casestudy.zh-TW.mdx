# 畢業生工作分配案例研究

[Clavié 等人 (2023)](https://arxiv.org/abs/2303.07142) 提供了一個提示工程，應用在中等規模文本分類應用上的案例研究。作者們以判斷一份工作是否適合畢業生為例子，評估一系列提示工程的技巧，並使用 GPT-3.5 (`gpt-3.5-turbo`) 回報結果。

這份研究顯示出 LLM 的表現，超越其他參與測試的模型，包含 DeBERTa-V3 中的基準模型。`gpt-3.5-turbo` 的表現和舊版 GPT-3 比起來，在所有關鍵指標中都明顯進步，但需要額外的輸出解析，因為它連接模板的能力似乎弱於其他變體。

在他們的提示工程方法中的主要發現是：

- 對於這類型的任務，不需要任何專家知識。在所有實驗中，`少量樣本的思維鏈提示 (few-shot CoT)`都比`零樣本提示 (zero-shot)`的結果更糟。
- 提示對引發正確推理的影響極大。只要求模型對給定的工作進行分類，得到的 F1 分數為 65.6，而先使用提示後工程模型的 F1 分數則達到了 91.7。
- 試圖強制模型遵照模板，在所有案例中都會降低表現（該行為在 GPT-4 早期的實驗中消失，但 GPT-4 的實驗在該論文之後出現）。
- 許多微小的修改對表現有極大影響。
  - 以下表格呈現了所有測試過的修改。
  - 給出合適的指令和重複關鍵點，看起來是影響表現最大的因素。
  - 給模型一個（人）名字這麼簡單的方式，就能提高 0.6 的 F1 分數。

### 本文中測試過的提示

| Short name | Description                                 |
|------------|---------------------------------------------|
| Baseline   | 提供一個職位，並詢問模型是否適合畢業生。           |
| CoT        | 在詢問前提供一些準確分類的例子。                  |
| Zero-CoT   | 讓模型在回答前逐步推理。                        |
| rawinst    | 藉由加入使用者訊息，來為模型提供角色和任務的指令。   |
| sysinst    | 在系統訊息中提供相關的角色和任務的指令。           |
| bothinst   | 將角色指令作為系統訊息，而任務指令則作為使用者訊息。 |
| mock       | 透過模擬一次對話來向模型說明任務指令。             |
| reit       | 透過重複指令中的關鍵點，來強化指令。              |
| strict     | 要求模型嚴格遵照給定模板回答。                   |
| loose      | 要求模型遵照給定模板提供最後答案。                |
| right      | 要求模型得出正確的結論。                        |
| info       | 提供額外資訊以定義常見的錯誤原因。                |
| name       | 給模型一個名字，用於在對話中稱呼它。              |
| pos        | 在詢問之前提供模型正向的回饋。                   |

### 所有提示的改變對表現的影響

|                                        | Precision     | Recall        | F1            | Template Stickiness    |
|----------------------------------------|---------------|---------------|---------------|------------------------|
| _Baseline_                             | _61.2_        | _70.6_        | _65.6_        | _79%_                  |
| _CoT_                                  | _72.6_        | _85.1_        | _78.4_        | _87%_                  |
| _Zero-CoT_                             | _75.5_        | _88.3_        | _81.4_        | _65%_                  |
| _+rawinst_                             | _80_          | _92.4_        | _85.8_        | _68%_                  |
| _+sysinst_                             | _77.7_        | _90.9_        | _83.8_        | _69%_                  |
| _+bothinst_                            | _81.9_        | _93.9_        | _87.5_        | _71%_                  |
| +bothinst+mock                         | 83.3          | 95.1          | 88.8          | 74%                    |
| +bothinst+mock+reit                    | 83.8          | 95.5          | 89.3          | 75%                    |
| _+bothinst+mock+reit+strict_           | _79.9_        | _93.7_        | _86.3_        | _**98%**_              |
| _+bothinst+mock+reit+loose_            | _80.5_        | _94.8_        | _87.1_        | _95%_                  |
| +bothinst+mock+reit+right              | 84            | 95.9          | 89.6          | 77%                    |
| +bothinst+mock+reit+right+info         | 84.9          | 96.5          | 90.3          | 77%                    |
| +bothinst+mock+reit+right+info+name    | 85.7          | 96.8          | 90.9          | 79%                    |
| +bothinst+mock+reit+right+info+name+pos| **86.9**      | **97**        | **91.7**      | 81%                    |

`Template stickiness` 表示的是，模型的回答有多常符合期望格式。
